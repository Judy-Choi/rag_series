{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일을 만들고, OpenAI api key 를 붙여넣기합니다.\n",
    "# OPENAI_API_KEY=sk-\n",
    "\n",
    "# 토큰 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터스토어 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "# connection = f\"postgresql+psycopg2://user:password@host:5432/name\",\n",
    "connection=f\"postgresql+psycopg2://rag_note:rag_note@localhost:5433/rag_note\"\n",
    "collection_name = \"my_db\"\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF 기반 질의 응답(Question-Answering)Permalink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드\n",
    "loader = PyPDFLoader(\"../data/[일반보험]_KB개인상해보험_보험약관.pdf\")\n",
    "document = loader.load()\n",
    "document[0].page_content[:200] # 내용 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 스토어에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. vector store 메소드 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Document object 의 metadata 컬럼에 문서 정보 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    text.metadata['product'] = \"KB개인상해보험\"\n",
    "    text.metadata['info'] = \"보험약관\"\n",
    "\n",
    "# 위 for 문을 List Comprehension 으로 다음과 같이 한 줄로 쓸 수 있다!\n",
    "# [text.metadata.update({'product': \"KB개인상해보험\", 'info': \"보험약관\"}) for text in texts]\n",
    "\n",
    "vector_store.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Document object 의 metadata 컬럼에 문서 정보 추가 (클래스 오버라이딩 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from sqlalchemy import text\n",
    "from typing import Any\n",
    "from overrides import overrides\n",
    "\n",
    "class OverridingPGVector(PGVector):\n",
    "\n",
    "    @overrides\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "\n",
    "    def _add_documents(self, documents: list[Document], **kwargs: Any) -> list[str]:\n",
    "        for doc in documents:\n",
    "            doc.metadata['product'] = \"KB개인상해보험\"\n",
    "            doc.metadata['info'] = \"보험약관\"\n",
    "\n",
    "        # 위 for 문을 List Comprehension 으로 다음과 같이 한 줄로 쓸 수 있다!\n",
    "        # [text.metadata.update({'product': \"KB개인상해보험\", 'info': \"보험약관\"}) for text in texts]\n",
    " \n",
    "        return self.add_documents(documents, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vector_store = OverridingPGVector(\n",
    "    # embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "    collection_name=collection_name,\n",
    "    # connection=connection,\n",
    "    connection_string=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vector_store._add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.similarity_search(query=\"보험금의 지급사유\",k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    # search_kwargs={\"k\": 3, \"fetch_k\": 2, \"lambda_mult\": 0.5},\n",
    "    search_kwargs={\"k\": 10, \"fetch_k\": 3, \"lambda_mult\": 0.5},\n",
    ")\n",
    "retriever.invoke(\"보험금의 지급사유\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-0125-preview\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "system_prompt = SystemMessage(content=\n",
    "        \"\"\"당신은 전문 상담원입니다. 아래 지침에 따라 사용자의 질문에 답변을 제공하세요.\n",
    "        ---------------------\n",
    "        1. 주어진 정보만 활용하여 답변을 제공하세요. 주어진 정보로 답변을 할 수 없는 경우, 정중하게 답변을 제공할 수 없다고 설명합니다.\n",
    "        2. 답변은 정제된 형식과 문어체로 작성하며, 친절하고 자세한 내용을 제공합니다.\n",
    "        ---------------------\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "template = (\n",
    "        \"Below is the context information.\\n\"\n",
    "        \"---------------------\\n\"\n",
    "        \"{context}\"\n",
    "        \"\\n---------------------\\n\"\n",
    "        \"Given the context information, provide a most relevant chunk to {query}.\"\n",
    "        \"If there is no title that matches, output '해당정보 존재하지 않음'.\"\n",
    "        \"Do not include the title on your final output.\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([system_prompt, template])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "chain = (\n",
    "        {\"context\": retriever | format_docs, \"query\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"보험금의 지급사유\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "def extract(retriever, system, prompt, llm, text_query):\n",
    "    chain = (\n",
    "            {\"context\": retriever | format_docs, \"query\": RunnablePassthrough()}\n",
    "            | ChatPromptTemplate.from_messages([system, template])\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    output = chain.invoke(text_query)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"보험금의 지급사유\"\n",
    "extract(retriever, system_prompt, prompt, llm, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"오늘 점심메뉴 추천\"\n",
    "extract(retriever, system_prompt, prompt, llm, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
